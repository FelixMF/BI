{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsXrIz0FxHYO",
        "outputId": "2b5ffdcb-8b35-425f-913c-4d56945ee654"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nuestro total de datos es 23527 y elegimos 3 para nuestro kfold con un nivel de confianza de 95.0%, lo que nos da lo siguiente:\n",
            "\n",
            "El error de testeo es= 0.0153\n",
            "\n",
            "El error de entrenamiento es= 0.0089\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "TOTAL_DATA = 23527\n",
        "KFOLD = 3\n",
        "CONFIDENCE_LEVEL = 0.95\n",
        "\n",
        "print(f\"Nuestro total de datos es {TOTAL_DATA} y elegimos {KFOLD} para nuestro kfold con un nivel de confianza de {CONFIDENCE_LEVEL*100}%, lo que nos da lo siguiente:\\n\")\n",
        "\n",
        "def calcular_error(n, confidence_level):\n",
        "    return math.sqrt((math.log(2) - math.log(1 - confidence_level))/(2*n))\n",
        "\n",
        "n_test = TOTAL_DATA / KFOLD\n",
        "test_error = calcular_error(n_test, CONFIDENCE_LEVEL)\n",
        "print(f\"El error de testeo es= {test_error:.4f}\\n\")\n",
        "\n",
        "n_train = n_test * 3\n",
        "train_error = calcular_error(n_train, CONFIDENCE_LEVEL)\n",
        "print(f\"El error de entrenamiento es= {train_error:.4f}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Cargar datos\n",
        "df = pd.read_csv(\"factVentasEtiquetados.csv\", encoding='latin-1', delimiter=';')\n",
        "\n",
        "# Función para obtener etiquetas únicas\n",
        "def obtener_etiquetas_unicas(df, columna_etiqueta):\n",
        "    etiquetas = df[columna_etiqueta]\n",
        "    print(\"Etiquetas únicas:\", etiquetas.unique() if etiquetas is not None else \"No se encontraron etiquetas\")\n",
        "    return etiquetas.unique()\n",
        "\n",
        "# Función para segmentar datos en matrices\n",
        "def segmentar_en_matrices(df, etiqueta):\n",
        "    etiquetas = obtener_etiquetas_unicas(df, etiqueta)\n",
        "    print(\"Etiquetas únicas:\", etiquetas)\n",
        "    matrices = {}\n",
        "    for etiqueta_unica in etiquetas:\n",
        "        matriz = df[df[etiqueta] == etiqueta_unica]\n",
        "        matrices[etiqueta_unica] = matriz\n",
        "    return matrices\n",
        "\n",
        "# Segmentar los datos en matrices\n",
        "matrices = segmentar_en_matrices(df, 'etiqueta')\n",
        "\n",
        "# Asignar matrices de manera segura verificando si las etiquetas existen\n",
        "matriz1 = matrices.get(1)\n",
        "matriz2 = matrices.get(2)\n",
        "matriz3 = matrices.get(3)\n",
        "\n",
        "# Dividir en conjuntos, manejando casos donde la matriz puede ser None\n",
        "def dividir_en_conjuntos(matriz):\n",
        "    if matriz is not None and not matriz.empty:\n",
        "        num_filas = len(matriz)\n",
        "        tamano_conjunto = num_filas // 3\n",
        "        resto = num_filas % 3\n",
        "        conjuntos = []\n",
        "        inicio = 0\n",
        "        for i in range(3):\n",
        "            fin = inicio + tamano_conjunto\n",
        "            if resto > 0:\n",
        "                fin += 1\n",
        "                resto -= 1\n",
        "            conjuntos.append(matriz.iloc[inicio:fin])\n",
        "            inicio = fin\n",
        "        return conjuntos\n",
        "    else:\n",
        "        return [None] * 7\n",
        "\n",
        "# Dividir en conjuntos para cada matriz\n",
        "conjuntos1 = dividir_en_conjuntos(matriz1)\n",
        "conjuntos2 = dividir_en_conjuntos(matriz2)\n",
        "conjuntos3 = dividir_en_conjuntos(matriz3)\n",
        "\n",
        "# Concatenar conjuntos válidos\n",
        "def concatenate_valid_sets(sets):\n",
        "    non_empty_sets = [s for s in sets if s is not None]\n",
        "    if non_empty_sets:\n",
        "        max_rows = max(s.shape[0] for s in non_empty_sets)\n",
        "        padded_sets = [np.pad(s.values, ((0, max_rows - s.shape[0]), (0, 0)), mode='constant') for s in non_empty_sets]\n",
        "        concatenated_sets = np.concatenate(padded_sets, axis=1)\n",
        "        return concatenated_sets\n",
        "    else:\n",
        "        # Handle the case where all sets are empty\n",
        "        print(\"Warning: All input sets are empty. Returning an empty array.\")\n",
        "        return np.array([])\n",
        "\n",
        "# Concatenar conjuntos válidos para cada test\n",
        "K1 = concatenate_valid_sets(conjuntos1)\n",
        "K2 = concatenate_valid_sets(conjuntos2)\n",
        "K3 = concatenate_valid_sets(conjuntos3)\n",
        "\n",
        "# Mezclar los datos de cada conjunto\n",
        "def mezclar_matriz(matriz):\n",
        "    # Crea una copia de la matriz original para no modificarla\n",
        "    resultado = matriz.copy()\n",
        "    # Mezcla las filas de la matriz\n",
        "    np.random.shuffle(resultado)\n",
        "    return resultado\n",
        "\n",
        "K1_Shuffle = mezclar_matriz(K1)\n",
        "K2_Shuffle = mezclar_matriz(K2)\n",
        "K3_Shuffle = mezclar_matriz(K3)\n",
        "\n",
        "# Guardar conjuntos en archivos CSV\n",
        "for i, K_Shuffle in enumerate([K1_Shuffle, K2_Shuffle, K3_Shuffle]):\n",
        "    pd.DataFrame(K_Shuffle).to_csv(f\"Test{i+1}.csv\", index=False)\n",
        "\n",
        "# Calcular el total de filas\n",
        "total_rows = min(K1_Shuffle.shape[0], K2_Shuffle.shape[0], K3_Shuffle.shape[0])\n",
        "\n",
        "# Generar una lista de índices aleatorios\n",
        "random_indices = list(range(total_rows))\n",
        "random.shuffle(random_indices)\n",
        "\n",
        "# Truncar los índices aleatorios para asegurarse de que estén dentro de los límites de la matriz\n",
        "random_indices = [idx % total_rows for idx in random_indices]\n",
        "\n",
        "# Seleccionar las filas correspondientes usando los índices aleatorios\n",
        "K1_Shuffle = K1_Shuffle[random_indices]\n",
        "K2_Shuffle = K2_Shuffle[random_indices]\n",
        "K3_Shuffle = K3_Shuffle[random_indices]\n",
        "\n",
        "# Dividir conjuntos para entrenamiento\n",
        "Training1 = pd.DataFrame(np.concatenate((K2_Shuffle, K3_Shuffle), axis=0))\n",
        "Training2 = pd.DataFrame(np.concatenate((K3_Shuffle, K1_Shuffle), axis=0))\n",
        "Training3 = pd.DataFrame(np.concatenate((K1_Shuffle, K2_Shuffle), axis=0))\n",
        "\n",
        "# Guardar conjuntos de entrenamiento en archivos CSV\n",
        "Training1.to_csv(\"Training1.csv\", index=False)\n",
        "Training2.to_csv(\"Training2.csv\", index=False)\n",
        "Training3.to_csv(\"Training3.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6_c-qh8xI-A",
        "outputId": "f3b45e91-6bf2-4fe3-91aa-1a7d9c6eb9ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Etiquetas únicas: [0 1 2 3]\n",
            "Etiquetas únicas: [0 1 2 3]\n"
          ]
        }
      ]
    }
  ]
}